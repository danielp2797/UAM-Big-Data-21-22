{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"title\">Aplicaciones de Análisis &ndash; Keras</div>\n",
    "<div class=\"subtitle\">Máster en Big Data y Data Science</div>\n",
    "<div class=\"author\">Carlos María Alaíz Gudín - Universidad Autónoma de Madrid</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuración inicial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<head><link rel=\"stylesheet\" href=\"style.css\"></head>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import gym\n",
    "\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "matplotlib.rc(\"image\", cmap=\"cividis\")\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeros pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras es una API de alto nivel que facilita las aplicaciones de ML.\n",
    "* En la práctica, muchas veces no hay necesidad de acceder directamente a TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso de Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las Redes Neuronales Artificiales (ANN) son modelos bioinspirados.\n",
    "\n",
    "<img src=\"figures/Neuron.svg?10\" alt=\"Neuron.\">\n",
    "\n",
    "* La unidad elemental es el perceptrón, o TLU.\n",
    "\n",
    "<img src=\"figures/TLU.svg?10\" alt=\"TLU.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: el perceptrón para regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aunque tiene otros *backends*, Keras se puede importar como parte de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras permite crear un modelo, equivalente al perceptrón de regresión (un modelo lineal) de forma sencilla, con métodos `fit` y `predict` asociados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=1,\n",
    "                                             activation=\"linear\",\n",
    "                                             input_shape=(1,),\n",
    "                                             name=\"TLU\")])\n",
    "model.compile(loss=\"mean_squared_error\")\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Entrenar el perceptrón sobre el conjunto de datos (`x_tr`, `y_tr`) usado anteriormente.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = tf.cast(tf.linspace(-1, 1, 101), dtype=tf.float32)\n",
    "y_tr = x_tr * 2 + 5\n",
    "\n",
    "################################\n",
    "# Insertar código.\n",
    "history = model.fit(x_tr, y_tr, epochs=2000)\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal weights:\", model.get_weights())\n",
    "\n",
    "plt.plot(x_tr.numpy(), y_tr.numpy(), \"*\", label=\"Observed\")\n",
    "plt.plot(x_tr.numpy(), model.predict(x_tr, verbose=0), \"-\", label=\"Model\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a las capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tradicionalmente, las ANN se organiza en capas de unidades.\n",
    "    * La salida de las neuronas de una capa se usa como entrada de la capa siguiente.\n",
    "\n",
    "<img src=\"figures/MLP.svg?15\" alt=\"MLP clásico.\">\n",
    "\n",
    "* En el contexto de TensorFlow, las capas se generalizan a funciones con una cierta estructura matemática conocida, que se pueden reutilizar y que tienen variables que pueden ser entrenadas.\n",
    "* Intuitivamente, se pueden considerar como las piezas fundamentales de un modelo de ML.\n",
    "    * Realizan una cierta transformación desde los datos de entrada a los datos de salida.\n",
    "    * Esta transformación se puede adaptar a los datos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principales tipos de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En Keras existen diversos tipos de capas:\n",
    "    * Capas básicas.\n",
    "    * Capa de convolución.\n",
    "    * Capas de *pooling*.\n",
    "    * Capas recurrentes.\n",
    "    * Capas de preproceso.\n",
    "    * Capas de normalización.\n",
    "    * Capas de regularización.\n",
    "    * Capas de cambio de forma.\n",
    "    * Capas de combinación.\n",
    "* En la siguiente tabla se muestran algunas de las principales capas básicas:\n",
    "\n",
    "| Tipo de Capa | Clase | Descripción                                                                          |\n",
    "|:-------------------|:------------------------|:-------------------------------------------------------------|\n",
    "| Capa de entrada    | `keras.Input`           | Capa que tomará  los valores de la entrada.                  |\n",
    "| Capa densa         | `keras.layers.Dense`    | Capa completamente conectada.                                |\n",
    "| Capa de activación| `keras.layers.Activation`| Capa para aplicar la función de activación a la salida de la capa anterior.|\n",
    "| Capa de *embedding*| `keras.layers.Embedding`| Capa para codificar valores discretos en un espacio continuo.|\n",
    "| Capa lambda     | `keras.layers.Lambda`     | Capa para aplicar una función arbitraria de TensorFlow.        |\n",
    "\n",
    "* Las capas no son más que funciones de TensorFlow, que se pueden aplicar a tensores que tengan las dimensiones apropiadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(3, input_shape=(3,))\n",
    "print(layer(tf.constant([[1, 1, 1]])).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"info\"><a href=\"https://keras.io/api/layers/\">Capas de Keras</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo secuencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los modelos secuenciales de Keras están concebidos como una pila de capas, donde cada capa toma como entrada un tensor, y produce como salida otro tensor.\n",
    "* Al crear el modelo secuencial, se especifica una lista de las capas que compondrán el modelo.\n",
    "* El modelo completo actúa como una función de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((3, 3))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        keras.layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modelo secuencial simplemente indica que cada capa se aplica sobre la salida de la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = keras.layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "print(layer3(layer2(layer1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modelo tiene un atributo `layers` con las capas que lo componen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede extraer un resumen del modelo, que muestra información útil como los parámetros entrenables que tiene.\n",
    "* También se puede representar en forma de grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modelo secuencial también se puede definir de forma incremental, añadiendo las capas sucesivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(3, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(4))\n",
    "\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por lo general, al crear una capa los pesos no se inicializan.\n",
    "* La primera vez que se aplica la capa se crean los pesos, con la dimensión adecuada para esa entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "print(\"Weights (before using the layer):\", layer.weights)\n",
    "\n",
    "y = layer(x)\n",
    "print(\"Weights (after using the layer): \", layer.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el caso de modelos secuenciales, ocurre algo similar: los pesos no se inicializan hasta que no se aplica el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(2),\n",
    "        keras.layers.Dense(3),\n",
    "        keras.layers.Dense(4),\n",
    "    ]\n",
    ")\n",
    "try:\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)\n",
    "\n",
    "print(\"\\nApplying the model...\")\n",
    "model(x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sin embargo, se puede forzar a que se creen especificando la dimensión inicial con una capa de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(3,)),\n",
    "        keras.layers.Dense(2),\n",
    "        keras.layers.Dense(3),\n",
    "        keras.layers.Dense(4),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* También se puede especificar el tamaño de la entrada como un parámetro de la primera capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(2, input_shape=(3,)),\n",
    "        keras.layers.Dense(3),\n",
    "        keras.layers.Dense(4),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Definir una red neuronal con $5$ capas densas de $10$ neuronas cada una, para un problema de $20$ dimensiones de entrada y $1$ salida.\n",
    "La función de activación será la sigmoidal para las capas ocultas, y la lineal para la capa de salida.\n",
    "* Observar el número de parámetros entrenables, y comprobar que concuerda con el teórico.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(10, input_shape=(20,), activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "################################\n",
    "\n",
    "print(\"\\nTotal parameters (theor.):\", (20 + 1) * 10 + 4 * ((10 + 1) * 10) + (10 + 1) * 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo funcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los modelos funcionales son más flexibles que los secuenciales.\n",
    "    * Capas compartidas.\n",
    "    * Múltiples entradas/salidas.\n",
    "    * Cualquier topología de conexión.\n",
    "* El modelo se define aplicando las capas como funciones, y especificando al final cuál será la entrada del modelo y cuál la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,))\n",
    "x = keras.layers.Dense(2)(inputs)\n",
    "x = keras.layers.Dense(3)(x)\n",
    "outputs = keras.layers.Dense(4)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Definir la red neuronal del ejercicio anterior usando la definición funcional.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "inputs = keras.Input(shape=(20,))\n",
    "x = keras.layers.Dense(10, activation=\"sigmoid\")(inputs)\n",
    "x = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
    "x = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
    "x = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
    "x = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar la creación, entrenamiento y predicción con un modelo de Keras, se usará el conjunto de datos de MNIST, accesible directamente desde Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr, y_tr), (x_te, y_te) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_tr = x_tr.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_te = x_te.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_tr = y_tr.astype(\"float32\")\n",
    "y_te = y_te.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El primer paso es crear el modelo (puede ser tanto secuencial como funcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,), name=\"digits\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\", name=\"predictions\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Definir un modelo lineal de clasificación binaria, de nombre `perceptron`, para un problema de $2$ dimensiones.\n",
    "Usar la aproximación funcional.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "inputs = keras.Input(shape=(2,))\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "perceptron = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "perceptron.summary()\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una vez creado el modelo, hay que compilarlo, especificando:\n",
    "    * La función de pérdida, que se minimizará durante el entrenamiento.\n",
    "    * El optimizador, es decir, el algoritmo que se usará para minimizar la pérdida.\n",
    "    * Las métricas con las que se evaluará el modelo para mostrar la evolución del entrenamiento.\n",
    "* Existen diversas opciones para cada uno.\n",
    "* Se pueden definir también nuevas pérdidas y métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Pérdida|Descripción   |Uso|\n",
    "|:--|:--|:--|\n",
    "|`mean_squared_error`  |Función estándar para problemas de regresión.     |Regresión|\n",
    "|`mean_squared_logarithmic_error`|Similar a la anterior, pero al ser logarítmica \"suaviza el castigo\".       |Regresión    |\n",
    "|`mean_absolute_error`|Apropiada cuando la distribución de datos tiene valores grandes o pequeños muy alejados del valor medio.|Regresión                           |\n",
    "|`binary_crossentropy` |Adecuada para problemas de clasificación binaria con valores $0$ y $1$.|Clasificación|\n",
    "|`hinge`|Pérdida de la SVM.|Clasificación|\n",
    "|`squared_hinge`|Suaviza la función de error anterior y resulta más sencilla en cómputo.|Clasificación|\n",
    "|`categorical_crossentropy`|Función de pérdida utilizado por defecto para problemas de clasificación múltiple (*hot-enconding*).|Clasificación |\n",
    "|`sparse_categorical_crossentropy`|Función de pérdida para problemas de clasificación múltiple (valores enteros).|Clasificación|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Optimizador|Velocidad|Calidad|\n",
    "|:--|:--|:--|\n",
    "|SGD|Baja|Alta|\n",
    "|Adagrad|Media|Alta|\n",
    "|RMSprop|Alta|Media-Alta|\n",
    "|Adam|Alta|Media o Alta|\n",
    "|Nadam|Alta|Media o Alta|\n",
    "|AdaMax|Alta|Media o Alta|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),                # Equivalently, \"rmsprop\".\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),   # Equivalently, \"sparse_categorical_crossentropy\".\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Compilar el modelo `perceptron` para minimizar la entropía binaria, usando ADAM, y monitorizando la precisión (*accuracy*).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "perceptron.compile(\n",
    "    optimizer=\"ADAM\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"info\"><a href=\"https://keras.io/api/losses/\">Pérdidas de Keras</a></div><br>\n",
    "<div class=\"info\"><a href=\"https://keras.io/api/optimizers/\">Optimizadores de Keras</a></div><br>\n",
    "<div class=\"info\"><a href=\"https://keras.io/api/metrics/\">Métricas de Keras</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tras compilar el modelo, se puede entrenar usando el método `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_tr,\n",
    "    y_tr,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_split=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Entrenar el modelo `perceptron` sobre el conjunto de datos definido a continuación.\n",
    "* Razonar si el modelo entrenado será capaz de resolver este problema o no.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pcp = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_pcp = np.array([0, 1, 1, 0])\n",
    "\n",
    "################################\n",
    "# Insertar código.\n",
    "history = perceptron.fit(x_pcp, y_pcp, epochs=100)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una vez entrenado, se puede predecir con el modelo mediante el método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test error, test accuracy:\", model.evaluate(x_te, y_te, verbose=0))\n",
    "\n",
    "pred = model.predict(x_te, verbose=0)\n",
    "print(pred.shape)\n",
    "print(pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El entrenamiento se puede realizar usando un `Dataset` de Keras, más eficiente y con opciones adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = tf.data.Dataset.from_tensor_slices((x_tr, y_tr))\n",
    "dataset_tr = dataset_tr.shuffle(buffer_size=1024).batch(64)\n",
    "print(dataset_tr)\n",
    "\n",
    "model.fit(dataset_tr, epochs=3)\n",
    "model.predict(x_te, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Obtener las predicciones del modelo `perceptron` sobre el conjunto de entrenamiento `x_pcp`.\n",
    "* Analizar el resultado obtenido.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "print(perceptron.predict(x_pcp, verbose=0))\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede almacenar un modelo con el método `save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para cargarlo basta con usar `keras.models.load_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = keras.models.load_model(\"model\")\n",
    "loaded.predict(x_te, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Almacenar el perceptrón en `\"perceptron\"`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "perceptron.save(\"perceptron\")\n",
    "!ls\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opciones avanzadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para motivar algunas opciones de Keras, se utilizará el conjunto de datos Fashion MNIST.\n",
    "* Este problema consiste en distinguir entre $10$ tipos distintos de ropa:\n",
    "\n",
    "| Etiqueta| Descripción|\n",
    "|:--|:--|\n",
    "|0 |\tT-shirt/top |\n",
    "|1 |\tTrouser |\n",
    "|2 |\tPullover |\n",
    "|3 |\tDress |\n",
    "|4 |\tCoat |\n",
    "|5 |\tSandal |\n",
    "|6 |\tShirt |\n",
    "|7 |\tSneaker |\n",
    "|8 |\tBag |\n",
    "|9 |\tAnkle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_tr, y_tr),(x_te, y_te) = mnist.load_data()\n",
    "x_tr = x_tr\n",
    "x_te = x_te\n",
    "\n",
    "print(\"Training size:\", x_tr.shape)\n",
    "print(\"Target size:  \", y_tr.shape)\n",
    "print(\"Maximum:      \", x_tr.max())\n",
    "print(\"Minimum:      \", x_tr.min())\n",
    "\n",
    "plt.imshow(x_tr[0])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Class {}\".format(y_tr[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambios de forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una gran cantidad de problemas de hoy en día tienen cierta estructura multidimensional.\n",
    "    * Señales.\n",
    "    * Imágenes.\n",
    "    * Vídeos.\n",
    "* Cuando se quieren procesar este tipo de datos con capas densas, es necesario \"aplanarlos\" mediante una capa `Flatten`, que los convierte en vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra una arquitectura para resolver el problema Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x_tr, y_tr, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Comprobar si el resultado en test, calculado en la siguiente celda, es aceptable o no.\n",
    "* Intentar mejorarlo sin modificar la arquitectura.\n",
    "\n",
    "<div class=\"notes\">\n",
    "\n",
    "* A veces el problema no está en el modelo, sino en los datos.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_te, y_te , verbose=0)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "x_tr = x_tr / 255.\n",
    "x_te = x_te / 255.\n",
    "\n",
    "model.fit(x_tr, y_tr, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_te, y_te, verbose=0)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Callbacks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los *callbacks* son una herramienta para especificar el comportamiento del modelo durante el entrenamiento, la evaluación, o la predicción.\n",
    "* Dos de los *callbacks* más importantes son:\n",
    "    * `EarlyStopping`: Permite detener el entrenamiento cuando no se produce mejora (en función de la métrica seleccionada):\n",
    "``` Python\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=0,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=False,\n",
    "    )\n",
    "```\n",
    "    * `ModelCheckpoint`: Guarda periódicamente el modelo durante el entrenamiento.\n",
    "``` Python\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        mode=\"auto\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "        **kwargs\n",
    "    )\n",
    "```\n",
    "* Se pueden definir *callbacks* propios, heredando de la clase `Callback`, y definiendo uno o varios de los siguientes métodos:\n",
    "| Método | Descripción |\n",
    "|:--|:--|\n",
    "|`on_(train\\|test\\|predict)_begin(self, logs=None)`| Invocada al empezar el entrenamiento/evaluación/predicción.|\n",
    "|`on_(train\\|test\\|predict)_end(self, logs=None)`| Invocada al terminar el entrenamiento/evaluación/predicción.|\n",
    "|`on_(train\\|test\\|predict)_batch_begin(self, batch, logs=None)`| Invocada al empezar a procesar un *batch* en entrenamiento/evaluación/predicción.|\n",
    "|`on_(train\\|test\\|predict)_batch_end(self, batch, logs=None)`| Invocada al terminar de procesar un *batch* en entrenamiento/evaluación/predicción.|\n",
    "|`on_epoch_begin(self, epoch, logs=None)`| Invocada al empezar una época de entrenamiento.|\n",
    "|`on_epoch_end(self, epoch, logs=None)`| Invocada al terminar una época de entrenamiento.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se define un *callback* para detener el entrenamiento si la pérdida en validación no mejora tras $3$ épocas, y otro para ir guardando el modelo (si mejora respecto al anterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=3)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"model\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se define un *callback* personalizado que detiene el entrenamiento si la precisión en entrenamiento supera el $60\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the model when the training accuracy arrives to 0.60.\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if (logs[\"sparse_categorical_accuracy\"] > 0.6):\n",
    "            print(\"Desired accuracy achieved\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "my_stopping = MyCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se entrena el modelo con los *callbacks* definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_tr,\n",
    "                    y_tr,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, checkpoint, my_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Modificar el código anterior para alcanzar una precisión mínima del $89\\%$ de entrenamiento.\n",
    "* Para evitar tiempos innecesarios de ejecución, parar el modelo si no se consigue mejorar la precisión de entrenamiento en $5$ épocas.\n",
    "* Almacenar el modelo automáticamente cuando mejore la predicción.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if (logs[\"sparse_categorical_accuracy\"] > 0.89):\n",
    "            print(\"Desired accuracy achieved\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "my_stopping = MyCallback()\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(x_tr,\n",
    "                    y_tr,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, checkpoint, my_stopping])\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"info\"><a href=\"https://keras.io/api/callbacks/\"><i>Callbacks</i> de Keras</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de la evolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La evolución del modelo se puede estudiar mediante TensorBoard, o con el historial del entrenamiento.\n",
    "* Para usar TensorBoard hay que almacenar la traza de Keras mediante un *callback* específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "history = model.fit(x_tr, y_tr, epochs=10, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización mediante Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización mediante TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evitar el sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uno de los problemas de las Redes Neuronales Profundas (*Deep Neural Networks*, DNNs) es su tendencia al sobreajuste, debido al alto número de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_tr, y_tr, validation_split=0.9, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Dada la evolución de los errores representada en la siguiente celda, discutir si se distingue sobreajuste del modelo.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Dropout*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una aproximación típica para regularizar una DNN es el *dropout*.\n",
    "* Durante el entrenamiento, un cierto porcentaje $r$ de las entradas a una cierta capa se ponen a $0$, mientras las otras se multiplican por $\\frac{1}{1 - r}$ para compensar el cambio de escala.\n",
    "* La red «aprende» a distribuir el procesamiento de la información, en lugar de confiar en unidades sueltas.\n",
    "* Durante la predicción sobre nuevos datos se usan todas las unidades de manera usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código genera un problema sencillo de regresión en una dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "n_pat = 64\n",
    "lim = 3\n",
    "noise = 1e0\n",
    "x_orig = np.linspace(- lim, lim, n_pat)\n",
    "x_long = np.linspace(- lim, lim, 10 * n_pat)\n",
    "y = np.square(x_orig) + noise * np.random.randn(n_pat)\n",
    "x = x_orig.reshape(-1, 1)\n",
    "\n",
    "plt.plot(x_orig, y, \"*\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Analizar la influencia de las capas de Dropout usadas en la siguiente celda.\n",
    "* Discutir si estas capas están evitando o no el sobreajuste.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (0.0, 0.2, 0.4, 0.6, 0.8):\n",
    "    inputs = keras.Input(shape=(1))\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\")(inputs)\n",
    "    layers = keras.layers.Dropout(d)(layers)\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\")(layers)\n",
    "    layers = keras.layers.Dropout(d)(layers)\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\")(layers)\n",
    "    outputs = keras.layers.Dense(1)(layers)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[\"mean_squared_error\"],\n",
    "    )\n",
    "\n",
    "    epochs = 1000\n",
    "    print(\"Fitting NN with dropout at {:2.0f}%...\".format(100 * d))\n",
    "    model.fit(x, y, epochs=epochs, verbose=0)\n",
    "    plt.plot(x_long, model.predict(x_long.reshape(-1, 1), verbose=0), label=\"Dropout {:.0f}%\".format(100 * d))\n",
    "\n",
    "plt.plot(x_orig, y, \"*k\", label=\"Observed\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las técnicas de regularización $L_1$ y $L_2$ son muy utilizadas en el entrenamiento de modelos de ML para evitar el sobreajuste.\n",
    "    * $L_1$ (Lasso Regression): Tiene como objetivo minimizar el valor absoluto de los pesos.\n",
    "    * $L_2$ (Ridge Regression, *weight decay*): Tiene como objetivo minimizar la magnitud al cuadrado de los pesos.\n",
    "* La principal diferencia entre $L_1$ y $L_2$ es que $L_1$ permite discriminar qué características son más importantes en el modelo, llevando a $0$ aquellas características de poco peso. $L_2$ es más eficiente computacionalmente.\n",
    "* En resumen, las técnicas de regularización $L_1$ y $L_2$ consiguen que el modelo tenga menos varianza, lo que ayuda a combatir el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Analizar la influencia de la regularización $L_2$ usada en la siguiente celda.\n",
    "* Discutir si esta regularización están evitando o no el sobreajuste.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in np.logspace(-5, 1, 7):\n",
    "    inputs = keras.Input(shape=(1))\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l))(inputs)\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l))(layers)\n",
    "    layers = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l))(layers)\n",
    "    outputs = keras.layers.Dense(1)(layers)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[\"mean_squared_error\"],\n",
    "    )\n",
    "\n",
    "    epochs = 1000\n",
    "    print(\"Fitting NN with regularization at {:.0e}...\".format(l))\n",
    "    model.fit(x, y, epochs=epochs, verbose=0)\n",
    "    plt.plot(x_long, model.predict(x_long.reshape(-1, 1), verbose=0), label=\"Regularization {:.0e}\".format(l))\n",
    "\n",
    "plt.plot(x_orig, y, \"*k\", label=\"Observed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra manera de evitar el sobreajuste es usar una gran cantidad de datos de entrenamiento.\n",
    "    * No siempre está disponible, dependerá del problema.\n",
    "* Una solución es generar nuevos datos (*data augmentation*).\n",
    "* Este proceso no es trivial, los datos generados tienen que ser relevantes para el problema.\n",
    "* Diferentes aproximaciones:\n",
    "    * Perturbar con ruido.\n",
    "    * Ajustar la distribución de los datos originales.\n",
    "    * Usar conocimiento experto sobre las variaciones en la vida real (algo particularmente útil con imágenes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se carga una imagen de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "china = load_sample_images().images[0]\n",
    "\n",
    "plt.imshow(china)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda perturba la imagen anterior, generando nuevas muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "\n",
    "x = keras.preprocessing.image.img_to_array(china)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "n_images = n_rows * n_cols\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    i += 1\n",
    "    if i > n_images:\n",
    "        break\n",
    "\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    plt.imshow(keras.preprocessing.image.array_to_img(batch[0]))\n",
    "    plt.title(\"Sample {}\".format(i))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Observar los diferentes efectos de distorsión en las imágenes anteriores, identificándolo con las opciones usadas en la generación.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Transfer Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para evitar el sobreajuste, se puede pre-entrenar el modelo en un conjunto de datos grande, y luego adaptarlo al problema en cuestión.\n",
    "* Esta aproximación se conoce como *transfer learning*:\n",
    "    1. Tomar un modelo entrenado con éxito sobre un conjunto de datos grande (el modelo completo, o solo una parte de él).\n",
    "    1. Añadir las capas necesarias para adaptarlo al problema en cuestión.\n",
    "    1. Entrenar las nuevas capas.\n",
    "    1. Entrenar todas las capas con una tasa de aprendizaje pequeña (*fine-tuning*).\n",
    "* Keras facilita esta aproximación.\n",
    "    * Proporciona varias arquitecturas pre-entrenadas.\n",
    "    * Permite seleccionar qué parámetros se entrenarán, dejando los demás congelados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repaso de Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un AutoEncoder (AE) es un tipo de red neuronal que aprende a replicar a la salida exactamente la misma información que recibe en la entrada.\n",
    "* Las capas de entrada y de salida deben tener el mismo número de unidades.\n",
    "* La clave está en la capa oculta, donde la red almacena una representación abstracta de la información.\n",
    "\n",
    "<img src=\"figures/AE.svg\" alt=\"AutoEncoder.\">\n",
    "\n",
    "* El aprendizaje de los AE es no supervisado.\n",
    "* El AE trata de modelar la identidad, $f(\\mathbf{x}_i) = \\mathbf{x}_i$.\n",
    "* El AE puede enfrentarse a este problema de dos formas:\n",
    "    1. Comportamiento deseado: El AE aprende a codificar (y posiblemente comprimir) los datos en la capa oculta.\n",
    "    2. Comportamiento trivial: El AE copia la entrada $\\mathbf{x}_i$ capa a capa, desde la entrada hasta la salida.\n",
    "* Es necesario forzar al AE a comprimir los datos para evitar el comportamiento trivial.\n",
    "* El AE queda divido en dos subredes.\n",
    "    1. El codificador, donde se realiza la extracción de características.\n",
    "    2. El decodificador, donde se invierte la extracción de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se carga el conjunto de dígitos MNIST, que se utilizará para ilustrar varios de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr, y_tr), (x_te, y_te) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Number of axis:   \", x_tr.ndim)\n",
    "print(\"Dimension (train):\", x_tr.shape)\n",
    "print(\"Dimension (test): \", x_te.shape)\n",
    "print(\"Data type:        \", x_tr.dtype)\n",
    "\n",
    "plt.imshow(x_tr[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# The pixels are transformed to the interval [0, 1].\n",
    "x_tr = x_tr.astype(\"float32\") / 255.\n",
    "x_te = x_te.astype(\"float32\") / 255.\n",
    "\n",
    "# Each image is converted into a 1-dimensional vector.\n",
    "x_tr_1D = x_tr.reshape(len(x_tr), -1)\n",
    "x_te_1D = x_te.reshape(len(x_te), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructor del Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para construir un AE en Keras basta con determinar la arquitectura:\n",
    "    * Capa de entrada, correspondiente a los datos que se van a codificar.\n",
    "    * Capas del codificador, encargadas de comprimir la información.\n",
    "    * Capas del decodificador, encargadas de descomprimir la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_builder(inp_lay, enc_lays, dec_lays, optimizer=\"adam\"):\n",
    "    # AE.\n",
    "    autoencoder = keras.Sequential([inp_lay] + enc_lays + dec_lays)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "    # Encoder.\n",
    "    encoder = keras.Sequential([inp_lay] + enc_lays)\n",
    "\n",
    "    # Decoder.\n",
    "    decoder = keras.Sequential([keras.Input(shape=enc_lays[-1].output_shape[1:])] + dec_lays)\n",
    "\n",
    "    return [autoencoder, encoder, decoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una primera forma de garantizar que el AE comprime la información es forzando a la capa oculta a tener una dimensión mucho menor que la dimensión de entrada.\n",
    "\n",
    "<img src=\"figures/AESmall.svg\" alt=\"AutoEncoder con dimensión reducida.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Completar la siguiente celda para definir la capa de entrada (`inp_lay`), las capas del codificador (`enc_lays`) y las capas del decodificador (`dec_lays`), de manera que en el AE resultante:\n",
    "    * La capa de entrada tome un vector de dimensión $784$ ($28 \\times 28$).\n",
    "    * El codificador tenga una única capa densa de tamaño `encoding_dim` (correspondiente a la dimensión reducida) con función de activación ReLU.\n",
    "    * El decodificador deshaga la codificación restaurando los datos a la dimensión original ($784$), con función de activación sigmoidal.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 16\n",
    "\n",
    "################################\n",
    "# Insertar código.\n",
    "inp_lay = keras.Input(shape=(x_tr_1D.shape[1],))\n",
    "enc_lays = [keras.layers.Dense(encoding_dim, activation=\"relu\")]\n",
    "dec_lays = [keras.layers.Dense(x_tr_1D.shape[1], activation=\"sigmoid\")]\n",
    "################################\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El AE se entrena simplemente minimizando el error cuadrático, como cualquier otra red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las imágenes se pueden codificar y decodificar aplicando a los datos originales las subredes del codificador y del decodificador, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D, verbose=0)\n",
    "decoded_imgs = decoder.predict(encoded_imgs, verbose=0)\n",
    "print(\"Prediction error: {:.3f}\".format(autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstrucción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos de las imágenes originales y reconstruidas se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Embedding*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede aplicar solo el codificador para realizar una reducción de dimensión de los datos iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1], label=\"Digit {}\".format(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Replicar el procedimiento anterior fijando la dimensión reducida a $2$.\n",
    "* ¿Tiene suficiente expresividad el AE?\n",
    "* ¿El *embedding* resultante es mejor o peor?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders *sparse*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una forma de garantizar la comprensión de información cuando la capa oculta es más grande que la de entrada es forzar a que los AE produzcan una codificación *sparse* de los datos (Sparse AE).\n",
    "    * Se utiliza una regularización que induzca dispersión en la capa oculta.\n",
    "* Solo se activan un subconjunto de las unidades ocultas a la vez.\n",
    "\n",
    "<img src=\"figures/AESparse.svg\" alt=\"Sparse AutoEncoder.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Completar la siguiente celda para definir la capa de entrada (`inp_lays`), las capas del codificador (`enc_lays`) y las capas del decodificador (`dec_lays`), de manera que en el AE resultante:\n",
    "    * La capa de entrada tome un vector de dimensión $784$ ($28 \\times 28$).\n",
    "    * El codificador tenga una única capa densa de tamaño `encoding_dim` (correspondiente a la dimensión extendida) con función de activación ReLU. Esta capa tendrá además una regularización para que la salida sea dispersa.\n",
    "    * El decodificador deshaga la codificación restaurando los datos a la dimensión original ($784$), con función de activación sigmoidal.\n",
    "\n",
    "<div class=\"notes\">\n",
    "\n",
    "* Para aplicar una regularización a la salida de una capa basta usar la opción `activity_regularizer` de la capa. En concreto, para que se induzca dispersión se puede usar una regularización de tipo $L_1$ (e.g. `activity_regularizer=keras.regularizers.l1(1e-3)`).\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 800\n",
    "\n",
    "################################\n",
    "# Insertar código.\n",
    "inp_lay = keras.Input(shape=(x_tr_1D.shape[1],))\n",
    "enc_lays = [keras.layers.Dense(encoding_dim,\n",
    "                               activation=\"relu\",\n",
    "                               activity_regularizer=keras.regularizers.l1(1e-3))]\n",
    "dec_lays = [keras.layers.Dense(x_tr_1D.shape[1], activation=\"sigmoid\")]\n",
    "################################\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El entrenamiento del Sparse AE garantizará que solo un subconjunto de las unidades se activan a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D, verbose=0)\n",
    "decoded_imgs = decoder.predict(encoded_imgs, verbose=0)\n",
    "print(\"Prediction error: {:.3f}\".format(autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstrucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1], label=\"Digit {}\".format(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La codificación de un Sparse AE es dispersa, por tanto muchas de las coordenadas son iguales a $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity: {:.2f}%\".format(100 * (encoded_imgs == 0).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué sucede si se pone a $0$ la regularización?\n",
    "* ¿Se comprime realmente la información?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders profundos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una ampliación de los AEs estándar es usar AEs profundos.\n",
    "    * Una DNN realiza la codificación.\n",
    "    * Una DNN (normalmente simétrica a la anterior) realiza la decodificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Completar la siguiente celda para definir la capa de entrada (`inp_lay`), las capas del codificador (`enc_lays`) y las capas del decodificador (`dec_lays`), de manera que en el AE resultante:\n",
    "    * La capa de entrada tome un vector de dimensión $784$ ($28 \\times 28$).\n",
    "    * El codificador tenga tres capas completamente conectadas con $128$, $64$ y $2$ unidades y activación ReLU.\n",
    "    * El decodificador deshaga la codificación restaurando los datos a la dimensión original ($784$), usando una arquitectura simétrica a la anterior, también de tres capas (las dos primeras con activación ReLU, y la última con activación sigmoidal).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "inp_lay = keras.Input(shape=(784,))\n",
    "enc_lays = [\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"relu\"),\n",
    "]\n",
    "dec_lays = [\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(784, activation=\"sigmoid\"),\n",
    "]\n",
    "################################\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para los Deep AEs se usa un entrenamiento similar al estándar en DNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D, verbose=0)\n",
    "decoded_imgs = decoder.predict(encoded_imgs, verbose=0)\n",
    "print(\"Prediction error: {:.3f}\".format(autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstrucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1],label=\"Digit {}\".format(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Considerando que la dimensión de codificación es $2$, ¿el *embedding* resultante es mejor o peor que los anteriores? ¿Por qué?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repaso de Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los modelos de ML suelen ser sensibles ante traslaciones de las entradas, de manera que un cambio como\n",
    "$$ \\begin{pmatrix} 0 & 1 & 3 & 5 & 0 & 0 \\end{pmatrix} \\to \\begin{pmatrix} 0 & 0 & 1 & 3 & 5 & 0 \\end{pmatrix} $$\n",
    "altera completamente las predicciones.\n",
    "* Este tipo de perturbaciones son muy comunes en algunos problemas reales, como los relacionados con imágenes.\n",
    "    * Dos imágenes con una ligera traslación deberían dar una salida similar.\n",
    "    * Sin embargo, en DNN estándar este no es el caso.\n",
    "* Las Redes Neuronales Convolucionales (*Convolutional Neural Networks*, CNNs) afrontan este problema mediante:\n",
    "    * Capas de convolución, que aplican filtros sobre las imágenes, detectando diferentes estructuras.\n",
    "    * Capas de *pooling*, que reducen la dimensión y proporcionan invarianza ante traslaciones.\n",
    "* La diferencia fundamental con respecto a los métodos de filtrado de imágenes tradicionales es que en las CNN los filtros no se fijan de antemano, sino que se ajustan durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolución de imágenes en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda carga una imagen de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "china = datasets.load_sample_images().images[0]\n",
    "china = china[:china.shape[0], :china.shape[0], :] / 255.0\n",
    "plt.imshow(china)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolución con diferentes filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aunque la potencia de las CNN es que los filtros se aprenden de los datos, en Keras se puede inicializar el valor a mano de las capas convolucionales para ver el efecto de distintos filtros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kv = []\n",
    "kv.append(np.array([[0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0]]))\n",
    "kv.append(np.array([[1, 1, 1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -1, -1]]))\n",
    "kv.append(kv[-1].T)\n",
    "kv.append(np.array([[-1, -1, -1],\n",
    "                    [-1, 8, -1],\n",
    "                    [-1, -1, -1]]))\n",
    "kv.append(np.array([[0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]]))\n",
    "kv.append(1 / 256 * np.array([[1, 4, 6, 4, 1],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [6, 24, 36, 24, 6],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [1, 4, 6, 4, 1]]))\n",
    "lv = (\"Identity\", \"Edge H\", \"Edge V\", \"Edges\", \"Sharpen\", \"Gaussian\")\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "inp = tf.constant([china])\n",
    "for k, l in zip(kv, lv):\n",
    "    def kernel_init(shape, dtype=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[:, :, 0, 0] = k\n",
    "        kernel[:, :, 1, 1] = k\n",
    "        kernel[:, :, 2, 2] = k\n",
    "        return kernel\n",
    "\n",
    "    model = keras.Sequential([keras.layers.Conv2D(3,\n",
    "                                                  k.shape,\n",
    "                                                  kernel_initializer=kernel_init,\n",
    "                                                  input_shape=china.shape)])\n",
    "    model.build()\n",
    "    out = model.predict(inp, verbose=0)[0]\n",
    "    out = np.clip(out, 0, 1)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(china)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(k)\n",
    "    plt.title(\"Kernel ({})\".format(l))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(out)\n",
    "    plt.title(\"Convoluted Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué efecto producirá un filtro formado por una matriz de tamaño $20 \\times 20$ con un valor contante de $\\frac{1}{400}$?\n",
    "* Comprobar el efecto producido modificando el código anterior.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "k = 1. / 400 * np.ones((20, 20))\n",
    "def kernel_init(shape, dtype=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[:, :, 0, 0] = k\n",
    "        kernel[:, :, 1, 1] = k\n",
    "        kernel[:, :, 2, 2] = k\n",
    "        return kernel\n",
    "\n",
    "model = keras.Sequential([keras.layers.Conv2D(3,\n",
    "                                              k.shape,\n",
    "                                              kernel_initializer=kernel_init,\n",
    "                                              input_shape=china.shape)])\n",
    "model.build()\n",
    "out = model.predict(inp, verbose=0)[0]\n",
    "out = np.clip(out, 0, 1)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(china)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(k)\n",
    "plt.title(\"Kernel (Constant)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(out)\n",
    "plt.title(\"Convoluted Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Convolucionales en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se modifica el conjunto de datos de MNIST para que cada ejemplo tenga dimensión $28 \\times 28 \\times 1$, ya que las capas convolucionales de Keras esperan que la última dimensión sea el canal (en este caso solo hay 1, ya que son imágnes en escala de grises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_tr = keras.utils.to_categorical(y_tr, num_classes=10)\n",
    "y_te = keras.utils.to_categorical(y_te, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales Convolucionales profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En Keras se pueden definir fácilmente las CNN usando las capas convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential()\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(32, kernel_size=(3,3),  activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "cnn.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "cnn.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(keras.layers.Dropout(0.2))\n",
    "cnn.add(keras.layers.Flatten())\n",
    "cnn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "cnn.add(keras.layers.Dropout(0.4))\n",
    "cnn.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Comprobar el número de parámetros libres de la segunda capa.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Insertar código.\n",
    "print(\"No. parameters (layer 1):\", 32 * (1 * 3 * 3 + 1))\n",
    "print(\"No. parameters (layer 2):\", 64 * (32 * 3 * 3 + 1))\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El entrenamiento de la CNN es similar al de cualquier otra DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn.fit(x_tr, y_tr, validation_split=0.75, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy: {:.3f}%\".format(100 * cnn.evaluate(x_te, y_te, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede pintar la evolución de los errores para detectar posibles problemas de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "preds = cnn.predict(x_te, verbose=0)\n",
    "y_te_t = np.argmax(y_te, axis=1)\n",
    "y_te_p = np.argmax(preds, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_te_t, y_te_p)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.axis(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repaso de Redes Neuronales Recurrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La mayoría de modelos de ML asumen independencia entre los ejemplos.\n",
    "* Hay muchas situaciones en los que esta hipótesis no es cierta, y los patrones son muy dependientes del contexto:\n",
    "    * Predicción de series temporales.\n",
    "    * Procesamiento del lenguaje natural.\n",
    "* Las Redes Neuronales Recurrentes (*Recurrent Neural Networks*, RNNs) tratan de paliar este problema a través de conexiones *backward*.\n",
    "* En concreto, las unidades *Long Short-Term Memory* (LSTM) son componentes diseñadas para retener información de patrones anteriores, a más largo plazo que otras RNNs estándar.\n",
    "* Estas unidades suelen tener los siguientes componentes:\n",
    "    * Celda, que constituye la memoria de la unidad LSTM.\n",
    "    * Puerta de entrada, que controla la influencia de la nueva entrada en la celda.\n",
    "    * Puerta de olvido, que controla cuánto se mantiene el valor en la celda.\n",
    "    * Puerta de salida, que controla cuánto se usa el valor de la celda para calcular la salida de la unidad.\n",
    "* Hay conexiones de entrada y salida a la LSTM (algunas recurrentes).\n",
    "* Los pesos de todas estas conexiones (incluidas las puertas) se aprenden durante el entrenamiento.\n",
    "* La red aprende qué patrones debe retener.\n",
    "\n",
    "<img src=\"figures/LSTM.svg\" alt=\"Unidad LSTM.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Recurrentes en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se genera una serie temporal sencilla como ejemplo para ilustrar las RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(- 8 * np.pi, 8 * np.pi, 513)\n",
    "x = np.sin(x)\n",
    "\n",
    "y = x[1:].reshape(- 1, 1)\n",
    "x = x[:-1].reshape(- 1, 1, 1)\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.3, shuffle=False)\n",
    "plt.plot(range(len(y_tr.ravel())), y_tr.ravel())\n",
    "plt.plot(range(len(y_tr.ravel()), len(y_tr.ravel()) + len(y_te.ravel())), y_te.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales Recurrentes LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En Keras existe un tipo de capa LSTM, que incluye tantas unidades LSTM como se especifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = keras.Sequential()\n",
    "rnn.add(keras.layers.LSTM(50, batch_input_shape=(1, 1, 1), stateful=True))\n",
    "rnn.add(keras.layers.Dense(1))\n",
    "\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_rnn = rnn.fit(x_tr, y_tr, epochs=10, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.reset_states()\n",
    "rnn.predict(x_tr, batch_size=1, verbose=0)\n",
    "preds_rnn = rnn.predict(x_te, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_te.ravel(), label=\"Real\")\n",
    "plt.plot(preds_rnn.ravel(), label=\"Pred\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x_te, y_te)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x_te, preds_rnn)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Observando la predicción anterior, ¿la salida de la RNN depende solo de su entrada (es decir, el valor en el instante anterior) o depende también del contexto? ¿Por qué?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Generativas Adversarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a las Redes Generativas Adversarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una aplicación no supervisada de las DNNs consiste en generar nuevas muestras, siguiendo una distribución previamente aprendida.\n",
    "    * Por ejemplo, generar caras realistas a partir de una base de datos de caras.\n",
    "* Surgen dos preguntas fundamentales:\n",
    "    1. ¿Cómo entrenar este tipo de modelos?\n",
    "    1. ¿Qué entrada usar para generar los nuevos ejemplos?\n",
    "* Las Redes Generativas Adversarias (*Generative Adversarial Networks*, GANs) afrontan este problema del siguiente modo:\n",
    "    1. Se sigue una aproximación adversaria para entrenar dos redes en un juego competitivo.\n",
    "    1. Se usa ruido aleatorio para generar las muestras.\n",
    "* Las GANs están compuestas por dos redes: una generadora y otra discriminatoria.\n",
    "* La red generadora recibe como entrada ruido, y produce como salida muestras de la distribución modelada.\n",
    "* La red discriminatoria recibe como entrada imágenes, y como salida trata de distinguir si son imágenes reales o generadas por la red generadora.\n",
    "* La magia de las GANs se produce en el entrenamiento adversario, donde se repite el siguiente proceso:\n",
    "    1. Se usa la generadora para producir imágenes falsas.\n",
    "    1. Se entrena la discriminadora para distinguir entre las imágenes falsas y las reales.\n",
    "    1. Se entrena la generadora para maximizar el error de la discriminadora.\n",
    "\n",
    "<img src=\"figures/GAN.svg\" alt=\"GAN.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Generativas Adversarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El discriminador es simplemente una red profunda que toma como entrada una imagen, y realiza una clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = keras.Sequential()\n",
    "\n",
    "    discriminator.add(keras.Input(shape=(28, 28, 1)))\n",
    "    discriminator.add(keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Conv2D(128, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Flatten())\n",
    "    discriminator.add(keras.layers.Dropout(0.2))\n",
    "    discriminator.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El generador es una red profunda que toma un vector (aleatorio) de una cierta dimensión, y produce como salida una imagen con el tamaño especificado.\n",
    "* Es común que su arquitectura sea simétrica a la del disciminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    generator = keras.Sequential()\n",
    "    \n",
    "    generator.add(keras.Input(shape=(100, )))\n",
    "    generator.add(keras.layers.Dense(7 * 7 * 128))\n",
    "    generator.add(keras.layers.Reshape((7, 7, 128)))\n",
    "    generator.add(keras.layers.Conv2DTranspose(128, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "generator = create_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La GAN es la concatenación del generador y el discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    gan_input = keras.Input(shape=(100,))\n",
    "    gan = keras.Model(inputs=gan_input, outputs=discriminator(generator(gan_input)))\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "    return gan\n",
    "\n",
    "gan = create_gan(discriminator, generator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función permite pintar muestras de las imágenes generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(generator, dim=(5, 5), figsize=(5, 5)):\n",
    "    examples = np.prod(dim)\n",
    "    noise = np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise, verbose=0)\n",
    "    generated_images = generated_images.reshape(examples, 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        image = generated_images[i]\n",
    "\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 101\n",
    "batch_size = 128\n",
    "\n",
    "(x_tr, y_tr), (x_te, y_te) = keras.datasets.mnist.load_data()\n",
    "x = x_tr[y_tr == 4].astype(\"float32\") / 255.\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "    print(\"Iteration: {}\".format(i), end=\"\\r\")\n",
    "    if (i % 10) == 0:\n",
    "        plot_generated_images(generator)\n",
    "\n",
    "    noise = np.random.normal(0, 1, [batch_size, 100])\n",
    "\n",
    "    generated_images = generator.predict(noise, verbose=0)\n",
    "    real_images = x[np.random.randint(low=0, high=x.shape[0], size=batch_size)]\n",
    "\n",
    "    X = np.concatenate([real_images, generated_images[:, :, :, 0]])\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "\n",
    "    y_dis = np.zeros(2 * batch_size)\n",
    "    y_dis[:batch_size] = 1.0\n",
    "\n",
    "    discriminator.trainable=True\n",
    "    discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "    noise = np.random.normal(0, 1, [batch_size, 100])\n",
    "    y_gen = np.ones(batch_size)\n",
    "\n",
    "    discriminator.trainable=False\n",
    "    gan.train_on_batch(noise, y_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Analizar el entrenamiento de la GAN.\n",
    "* ¿Por qué se modifican las etiquetas de los patrones?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por Refuerzo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al Aprendizaje por Refuerzo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Además del Aprendizaje Supervisado y el Aprendizaje No Supervisado, existe otro paradigma denominado Aprendizaje por Refuerzo (*Reinforcement Learning*, RL), que trata de determinar qué acciones debe tomar un agente en un cierto entorno para maximizar una recompensa.\n",
    "* Este tipo de problemas suele formalizarse como un Proceso de Markov de Decisión:\n",
    "    * $s_t$ es el estado a tiempo $t$.\n",
    "    Algunos estados son terminales, en el sentido de que terminan el episodio.\n",
    "    * $r_t$ es la recompensa obtenida a tiempo $t$.\n",
    "    * $a_t$ es la acción que toma el agente a tiempo $t$.\n",
    "    * $p_s(s_2 | s_1, a)$ es el modelo de transición, que modela la probabilidad de ir del estado $s_1$ al estado $s_2$ cuando se toma la acción $a$.\n",
    "    * $p_r(r | s, a)$ es el modelo de recompensa, que modela la probabilidad de obtener una recompensa $r$ desde el estado $s$ cuando se toma la acción $a$.\n",
    "* El objetivo del RL es encontrar una política, una probabilidad $\\pi(a | s)$ que maximice la recompensa esperada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolución de problemas de RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si las probabilidades reales $p_s$ y $p_r$ se conocen, entonces la política óptima $\\pi(a | s)$ puede calcularse mediante programación dinámica.\n",
    "* En general estas distribuciones son desconocidas, así que se pueden seguir dos aproximaciones distintas:\n",
    "    1. Métodos basados en modelo, que tratan de modelar $p_s$ y $p_r$, y luego estimar $\\pi(a | s)$ a partir de estos modelos.\n",
    "    1. Métodos *model-free*, que tratan directamente de optimizar la política $\\pi(a | s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método Actor-Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En este método el agente aprende a predecir, a partir del estado actual, dos salidas distintas:\n",
    "    1. La política, $\\pi(a | s)$. La parte del agente encargada de esta salida es el actor.\n",
    "    1. La recompensa estimada en el futuro. La parte del agente encargada de esta salida es el crítico.\n",
    "* El crítico aprende comparando la recompensa obtenida en episodios reales con su predicción, y haciendo descenso por gradiente.\n",
    "* Por otro lado, el actor utiliza *policy gradient* (estima el gradiente mediante el método de Montecarlo), modificado para usar la información producida por el crítico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje por Refuerzo en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos: CartPole v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Este problema consiste en un poste articulado sobre un carro, que se mueve por una vía.\n",
    "* El poste comienza vertical, y el objetivo es impedir que caiga cambiando la velocidad del carro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Índice| Observación| Mín | Máx|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| 0 | Posición del Carro | $$-2.4$$ | $$2.4$$ |\n",
    "| 1 | Velocidad del Carro  | $$-\\infty$$ | $$\\infty$$ |\n",
    "| 2 | Ángulo del Poste | $$\\sim -41.8^\\circ$$ | $$\\sim 41.8^\\circ$$ |\n",
    "| 3 | Velocidad del Poste (en el Extremo) | $$-\\infty$$ | $$\\infty$$ |\n",
    "\n",
    "* El estado inicial es aleatorio, según una uniforme $\\pm 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acciones y recompensa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Índice | Acción |\n",
    "|:-:|:-:|\n",
    "| 0 | Empujar el carro hacia la izquierda |\n",
    "| 1 | Empujar el carro hacia la derecha|\n",
    "\n",
    "* La recompensa es $1$ para cada instante de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fin del episodio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El episodio termina si se cumple cualquiera de las siguientes condiciones:\n",
    "    1. El ángulo del poste es mayor que $\\pm 12^\\circ$.\n",
    "    2. La posición del carro es mayor que $\\pm 2.4$ (el centro del carro abandona la imagen).\n",
    "    3. El episodio dura más de $500$ pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Política aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda crea el entorno del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código genera un episodio siguiendo la política especificada (si no hay modelo, se selecciona la siguiente acción aleatoriamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(env, early_stop=True, model=None, n_steps=500):\n",
    "    state = env.reset()\n",
    "    for i in range(n_steps):\n",
    "        env.render()\n",
    "        if model is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action_probs, _ = model.predict(tf.expand_dims(tf.convert_to_tensor(state), 0), verbose=0)\n",
    "            p = np.squeeze(action_probs)\n",
    "            action = np.random.choice(len(p), p=p)\n",
    "        state, _, done, _ = env.step(action)\n",
    "        if early_stop and done:\n",
    "            print(\"Finished after {} steps\".format(i))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sequence(env, model=None, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *Actor-Critic* con Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda configura el modelo.\n",
    "El parámetro $\\gamma$ (variable `gamma`) determina el olvido o factor de descuento de las recompensas pasadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "max_steps_per_episode = 10000\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda construye la red neuronal que implementará tanto el actor como el crítico, compartiendo la entrad y la capa oculta, y usando una capa de salida diferente para la política (actor) y la estimación de recompensa (crítico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "num_hidden = 128\n",
    "\n",
    "inputs = keras.layers.Input(shape=(num_inputs,))\n",
    "common = keras.layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
    "action = keras.layers.Dense(num_actions, activation=\"softmax\")(common)\n",
    "critic = keras.layers.Dense(1)(common)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[action, critic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Cuál es la función de activación de cada capa de salida?\n",
    "¿Por qué?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El entrenamiento consiste básicamente en completar episodios, acumulando la pérdida tanto del actor como del crítico a lo largo de todos los pasos de un episodio.\n",
    "* Durante cada episodio, se sigue la política aprendida hasta el momento.\n",
    "* Cuando finaliza el episodio, se actualizan los pesos del agente a partir del gradiente de ambas pérdidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "huber_loss = keras.losses.Huber()\n",
    "action_probs_history = []\n",
    "critic_value_history = []\n",
    "rewards_history = []\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "\n",
    "while True:\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        for timestep in range(1, max_steps_per_episode):\n",
    "            # Show the attemps.\n",
    "            env.render()\n",
    "\n",
    "            # Estimate the policy (prediction of the next actions) and the future rewards using the model.\n",
    "            state = tf.convert_to_tensor(state)\n",
    "            state = tf.expand_dims(state, 0)\n",
    "            action_probs, critic_value = model(state)\n",
    "            critic_value_history.append(critic_value[0, 0])\n",
    "\n",
    "            # Choose random action using the policy.\n",
    "            action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
    "            action_probs_history.append(tf.math.log(action_probs[0, action]))\n",
    "\n",
    "            # Apply the sampled action.\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards_history.append(reward)\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Once the episode is finished, update running reward to check condition for solving.\n",
    "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
    "\n",
    "        # Calculate the real expected value from rewards.\n",
    "        returns = []\n",
    "        discounted_sum = 0\n",
    "        for r in rewards_history[:-1]:\n",
    "            discounted_sum = r + gamma * discounted_sum\n",
    "            returns.insert(0, discounted_sum)\n",
    "        returns = np.array(returns)\n",
    "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
    "        returns = returns.tolist()\n",
    "\n",
    "        # Compute the loss values (both for Actor and Critic) to update the network.\n",
    "        history = zip(action_probs_history, critic_value_history, returns)\n",
    "        actor_losses = []\n",
    "        critic_losses = []\n",
    "        for log_prob, value, ret in history:\n",
    "            diff = ret - value\n",
    "            actor_losses.append(-log_prob * diff)\n",
    "            critic_losses.append(huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0)))\n",
    "\n",
    "        # Update the weights through backpropagation.\n",
    "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Clear variables.\n",
    "        action_probs_history.clear()\n",
    "        critic_value_history.clear()\n",
    "        rewards_history.clear()\n",
    "\n",
    "    episode_count += 1\n",
    "    if episode_count % 10 == 0:\n",
    "        print(\"Running reward: {:6.2f} at episode {:3d}\".format(running_reward, episode_count))\n",
    "\n",
    "    if running_reward > 80:\n",
    "        print(\"Solved at episode {}!\".format(episode_count))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado, el modelo es capaz de generar secuencias mucho más largas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sequence(env, model=model)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.8px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
