{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"title\">Aplicaciones de Análisis &ndash; Predicción de Series Temporales: Energía Solar</div>\n",
    "<div class=\"subtitle\">Máster en Big Data y Data Science</div>\n",
    "<div class=\"author\">Ángela Fernández Pascual - Universidad Autónoma de Madrid</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se van a resumir los pasos a realizar para analizar y predecir una serie temporal, así como los paquetes y funciones necesarios para su ejecución en Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuración**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<head><link rel=\"stylesheet\" href=\"style.css\"></head>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<head><link rel=\"stylesheet\" href=\"style.css\"></head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los paquetes de Python necesarios para trabajar con series temporales son:\n",
    "\n",
    "* **numpy**\n",
    "* **pandas**\n",
    "* **matplotlib**\n",
    "* **statsmodels**\n",
    "* **sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "matplotlib.rc('figure', figsize=(15, 5))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.seasonal as tsa\n",
    "import statsmodels.graphics.tsaplots as tsaplots\n",
    "\n",
    "from os.path import isfile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Carpeta de salida\n",
    "output_folder='./Output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos como serie temporal estacionaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar los datos originales de **Energía Solar** utilizados en el notebook de Análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = pd.read_csv('solar.csv',\n",
    "                    header=0, parse_dates=[0], index_col=[0], usecols=[0, 1], dayfirst=True, \n",
    "                    squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos el formato y las peculiaridades estadísiticas de este conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción utilizando Modelos Clásicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en conjuntos de entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en cualquier método de predicción lo primero que debemos hacer es dividir nuestro conjunto en train y test. Además en este caso, vamos a considerar un único conjunto de validación para el proceso de bascktesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tr = solar['2014']\n",
    "s_va = solar['2015']\n",
    "s_te = solar['2016']\n",
    "\n",
    "n_tr = len(s_tr)\n",
    "n_va = len(s_va)\n",
    "n_te = len(s_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_va.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_te.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué conclusiones se pueden sacar a la vista de las estadísticas de los distintos conjuntos formados?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prácticamente todos los modelos que vamos a estudiar forman parte de la familia de modelos autorregresivos, y en el paquete \n",
    "**statsmodels** todos ellos se pueden ver como casos particulares de la clase [SARIMAX](https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html#statsmodels.tsa.statespace.sarimax.SARIMAX). Aunque existen en el paquete otras clases y funciones para ejecutar estos modelos, este es sin duda el más actualizado.\n",
    "\n",
    "En SARIMAX, para entrenar un modelo los argumentos básicos son:\n",
    " * **endog**: la serie temporal a utilizar.\n",
    " * **order**: una tupla con tres números (p, d, q) correspondientes al parámetro p de AR, al parámetro d para el model ARIMA y al parámetro d de MA.\n",
    " * **exog** \\[optional\\]: la serie temporal con otros parámetros a considerar.\n",
    " * **sesonal_order** \\[optional\\]: una tupla (P,D,Q,s) con los parámetros para la componente estacional, indicando el parámetro de AR, diferencias, parámetro de MA y la periodicidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independientemente del modelo que utilicemos, siempre debemos estimar sus parámetros sobre los **datos de train** utilizando primero la llamada al constructor del modelo en cuestión. A este modelo hay que pasarle además de los datos, el valor de los hiperparámetros que queremos probar.\n",
    "\n",
    "Una vez fijado el modelo lo entrenamos con la función **fit()**. Con ella se estimarán los valores de los parámetros. Estos valores se pueden ver o bien con **model.params** o bien con la función **model.summary()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SARIMAX_TRAIN\n",
    "This function fit a SARIMAX model with the specified hyperparameters. \n",
    "If a period is given, it will make the TS stacionary via the differentiation method.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "s : array_like\n",
    "    The complete temporal series (joined in one array or dataframe training, \n",
    "    validation and test sets).\n",
    "\n",
    "order : iterable or iterable of iterables\n",
    "        The (p,d,q) order of the model for the number of AR parameters, differences, \n",
    "        and MA parameters.\n",
    "\n",
    "n_tr : integer\n",
    "       The size of the training to be considered.\n",
    "        \n",
    "period : integer\n",
    "         Period to compute the differentiated series.\n",
    "\n",
    "seasonal_order : iterable, optional\n",
    "                 The (P,D,Q,s) order of the seasonal component of the model for \n",
    "                 the AR parameters, differences, MA parameters, and periodicity.\n",
    "                 \n",
    "exog: array_like, optional\n",
    "      The exogenous series (joined in one array or dataframe training, \n",
    "    validation and test sets).\n",
    "\"\"\"\n",
    "\n",
    "def SARIMAX_train(s, order, n_tr, period=0, seasonal_order=(0,0,0,0), exog=None):\n",
    "    s_aux = s.copy()\n",
    "    if (period != 0):\n",
    "        s_aux = s_aux.diff(periods=period)\n",
    "    \n",
    "    if exog is None:\n",
    "        exogTrain = None\n",
    "    else:\n",
    "        exogTrain = exog[:n_tr].to_numpy()\n",
    "        \n",
    "    tr_mod = sm.tsa.SARIMAX(s_aux[:n_tr].to_numpy(), exog=exogTrain, \n",
    "                            order=order, seasonal_order=seasonal_order)\n",
    "    #The parameter values are estimated using just the training data\n",
    "    tr_res = tr_mod.fit()\n",
    "\n",
    "    #Extend the parameters to the whole series\n",
    "    if exog is None:\n",
    "        exogExtend = None\n",
    "    else:\n",
    "        exogExtend = exog.to_numpy()\n",
    "        \n",
    "    res = tr_res.extend(s_aux.to_numpy(), exog=exogExtend)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear un **primer modelo** para nuestra serie de datos. Para definirlo, recordemos los diagramas de la ACF y PACF que vimos durante el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_stacionary = pd.read_csv('solar_estacionaria.csv',\n",
    "                    header=0, parse_dates=[0], index_col=[0], usecols=[0, 1], dayfirst=True, \n",
    "                    squeeze=True)\n",
    "\n",
    "plt.figure(); tsaplots.plot_acf(series_stacionary); plt.show()\n",
    "plt.figure(); tsaplots.plot_pacf(series_stacionary); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* A la vista de los datos de ACF y PACF obtenidos en el análisis, ¿qué modelo (AR, MA o ARMA) cuadra mejor?\n",
    "\n",
    "* ¿Qué valores de p y q tienen sentido para una primera prueba?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINICIÓN DEL MODELO\n",
    "p = 2\n",
    "q = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours=24\n",
    "mod = SARIMAX_train(solar, (p, 0, q), n_tr+n_va, period=n_hours)\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* A la vista del modelo construido, ¿qué retraso es más importante, cuál es el que más informaicón aporta al modelo?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar los resultados del entrenamiento, una buena idea suele ser analizar los **residuos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = pd.DataFrame(mod.resid, columns=['Residuals'])\n",
    "residuals.plot()\n",
    "plt.show()\n",
    "residuals.plot(kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué nos están diciendo estos residuos? ¿Parecen valores sensatos?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos a continuación una función que nos permita predecir a distintos horizontes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SARIMAX_PREDICT\n",
    "This function predict using a SARIMAX model previously defined.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "model : previous trained model\n",
    "\n",
    "s : array_like\n",
    "    The complete temporal series (joined in one array or dataframe trainning, \n",
    "    validation and test sets).\n",
    "\n",
    "start : integer\n",
    "        Index where to start predicting.\n",
    "\n",
    "end : integer\n",
    "       Index where to end the prediction.\n",
    "        \n",
    "horizon : integer\n",
    "          Horizon for the prediction (0 by default).\n",
    "\n",
    "period : integer\n",
    "         Period to de-compute the differentiated series (0 by default). \n",
    "\"\"\"\n",
    "def SARIMAX_predict(model, s, start, end, horizon=0, period=0):\n",
    "    if horizon == 0:\n",
    "        pred = model.predict(start=start, end=end - 1, dynamic=False)\n",
    "    else:\n",
    "        pred = []\n",
    "        for i in range(start, end):\n",
    "            print('\\r\\tComputing... (%5d / %5d)' % (i, end), end='')\n",
    "            pred.append(model.predict(start=i-horizon, end=i, dynamic=True)[horizon])\n",
    "        pred = np.array(pred)\n",
    "        print('\\r%50s\\r' % ' ', end='')\n",
    "    if (period != 0):\n",
    "        return pred + s[start - period:end - period].to_numpy()\n",
    "    else:\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horizon=6\n",
    "n_hours=24\n",
    "\n",
    "start=n_tr + n_va\n",
    "end=n_tr + n_va + n_te\n",
    "\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/pred0_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)\n",
    "    else:\n",
    "        pred = SARIMAX_predict(mod, solar, start, end, h, \n",
    "                               period=n_hours)\n",
    "        np.save(file, pred)\n",
    "    plt.plot(pred[1100:1200], label='H%02d' % (h + 1))\n",
    "    \n",
    "#While predicting we plot the first 100 points as an example\n",
    "y = solar[start+1100:start+1200]\n",
    "x = y.index\n",
    "plt.plot(y.to_numpy(), 'k', linewidth=2, label='Real')\n",
    "xticks = np.arange(len(y), step=n_hours)\n",
    "plt.xticks(xticks, x[xticks])\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Observando la gráfica obtenida, ¿qué conclusiones podemos extraer?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conocer la bondad de la predicción realizada, por un lado podemos pintar los datos predichos frente a los reales (estamos ante un escenario de pruebas) y ver si las dos series se parecen, como hemos hecho en el apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, siempre viene bien una medida cuantitativa que nos permita comparar de forma objetiva el resultado con el obtenido con otros modelos. Aunque esta medida dependerá del problema a resolver y de los objetivos fijados, una de las medidas típicas es el error cuadrático medio. En el contexto de las energía renovables también es muy utilizado el error absoluto medio, por ser el utilizado en los mercados de energía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, el problema al que nos enfrentamos tiene como particularidad una estacionalidad diaria, lo que nos permite realizar un análisis por hora que puede facilitarnos mucha información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ERRORS_BY_HOUR\n",
    "This function computes the errors (MAE or MSE), first for the whole test dataset, \n",
    "and then per hour separetely.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "true : array_like\n",
    "    The real temporal series during a particular testing period. \n",
    "\n",
    "pred : array_like\n",
    "    The predicted temporal series during a particular testing period. \n",
    "\n",
    "MAE : boolean, True by default\n",
    "      True for computing mean_absolute_error, False for computing mean_squared_error\n",
    "\n",
    "\"\"\"\n",
    "def errors_by_hour(true, pred, MAE=True):\n",
    "    ind = true.index\n",
    "    ind_hour = ind.hour\n",
    "    min_hour = ind_hour.min()\n",
    "    max_hour = ind_hour.max()\n",
    "    \n",
    "    if MAE==True:\n",
    "        maes = [mean_absolute_error(true, pred)]\n",
    "        for hour in range(min_hour, max_hour + 1):\n",
    "            maes.append(mean_absolute_error(true[ind_hour == hour].to_numpy(), \n",
    "                                            pred[ind_hour == hour]))\n",
    "        return np.arange(min_hour, max_hour + 1), maes\n",
    "    else: \n",
    "        mses = [mean_squared_error(true, pred)]\n",
    "        for hour in range(min_hour, max_hour + 1):\n",
    "            mses.append(mean_squared_error(true[ind_hour == hour].to_numpy(), \n",
    "                                           pred[ind_hour == hour]))\n",
    "        return np.arange(min_hour, max_hour + 1), mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_h=[]\n",
    "n_horizon=6\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/pred0_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)\n",
    "    hours, maes = errors_by_hour(solar[start:end], pred, MAE=True)\n",
    "    maes_h.append(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos pintar los errores por hora a horizonte 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=0\n",
    "print('Total MAE: %.2f' % (maes_h[horizon][0]))\n",
    "for h in range(24):\n",
    "    print('MAE Hora %02d: %.2e' % (h, maes_h[horizon][h+1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué te dicen estos errores por hora? ¿Crees que son sensatos?\n",
    "* ¿Y si evaluamos el horizonte 5? ¿Sacamos las mismas conclusiones? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular los errores por horizonte, y compararlos con una gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horizon=6\n",
    "\n",
    "maes_t = np.array(maes_h)[:, 0]\n",
    "maes = np.array(maes_h)[:, 1:]\n",
    "for h in range(n_horizon):\n",
    "    plt.plot(hours, maes[h, :], label='H%02d' % (h + 1))\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, maes_t[h]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué se aprecia en la gráfica anterior?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una parte importante a la hora de realizar un modelo es validar el mismo y elegir así los valores de los hiperparámetros. En ST no podemos utilizar CV porque necesitamos mantener la ordenación temporal. Al proceso de validación en ST se le denomina **backtesting**, y vamos a utilizar para este caso un único conjunto de validación realizando una búsqueda en rejilla de los mejores valores para nuestros hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código recoge en una función la metodología de validación para los hiperparámetros p y q que definen el orden de un modelo autorregresivo simpe. Nótese que al estar pegado al problema de las energías renovables, se optimizan los valores de los hiperparámetros en términos de MAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VALIDATE\n",
    "It obtains the optimal hyperparameters, based on the MAE as score function\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "horizon : integer\n",
    "          Horizon for the prediction.\n",
    "\n",
    "s : array_like\n",
    "    The complete temporal series (joined in one array or dataframe trainning, \n",
    "    validation and test sets).\n",
    "\n",
    "n_tr : integer\n",
    "       The size of the training set to be considered.\n",
    "\n",
    "n_va : integer\n",
    "       The size of the validation set to be considered.\n",
    "\n",
    "period : integer\n",
    "         Period to de-compute the differentiated series (0 by default). \n",
    "\"\"\"\n",
    "def validate(horizon, s, n_tr, n_va, period=0):\n",
    "    vec_p = np.arange(10)\n",
    "    vec_q = np.arange(10)\n",
    "    \n",
    "    best_e = np.inf\n",
    "    \n",
    "    true = s[n_tr:n_tr + n_va].to_numpy()\n",
    "    for p in vec_p:\n",
    "        for q in vec_q:\n",
    "            try:\n",
    "                model = SARIMAX_train(s, (p, 0, q), n_tr, period=period)\n",
    "                pred = SARIMAX_predict(model, s, n_tr, n_tr + n_va, horizon, period=period)\n",
    "                e = mean_absolute_error(true, pred)\n",
    "            except Exception as exc:\n",
    "                e = np.inf\n",
    "            if (e < best_e):\n",
    "                best_e = e\n",
    "                best_p = p\n",
    "                best_q = q\n",
    "            \n",
    "            print('%d %d => %.4f' % (p, q, e))\n",
    "    \n",
    "    order = (best_p, 0, best_q)\n",
    "    print('\\tBest:', order)\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a validar el modelo para horizonte 0 y utilizaremos estos valores para el resto de horizontes. Se pueden obtener distintos hiperparámetros para cada horizonte a considerar, mejorando así el resultado obtenido (aunque a costa de mucho esfuerzo computacional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '%s/order.npy' % (output_folder)\n",
    "if isfile(file):\n",
    "    order = np.load(file)\n",
    "    print(order)\n",
    "else:\n",
    "    order = validate(0, solar, n_tr, n_va - 6, period=n_hours)\n",
    "    np.save(file, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué modelo ha elegido?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los mejores hiperparámetros, debemos volver a entrenar el modelos con los conjuntos de entrenamiento y validación (para contar con la información más reciente) y predecimos sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_h = []\n",
    "n_horizon=6\n",
    "n_hours=24\n",
    "\n",
    "start=n_tr + n_va\n",
    "end=n_tr + n_va + n_te\n",
    "\n",
    "#Reentrenamos con todo el conjunto de entrenamiento y validación \n",
    "mod = SARIMAX_train(solar, order, n_tr + n_va, period=n_hours)\n",
    "\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/predARval_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)\n",
    "    else:\n",
    "        pred = SARIMAX_predict(mod, solar, start, end, h, period=n_hours)\n",
    "        np.save(file, pred)\n",
    "    plt.plot(pred[1100:1200], label='H%02d' % (h + 1))\n",
    "    hours, maes = errors_by_hour(solar[start:end], pred, MAE=True)\n",
    "    maes_h.append(maes)\n",
    "    \n",
    "y = solar[start+1100:start+1200]\n",
    "x = y.index\n",
    "plt.plot(y.to_numpy(), 'k', linewidth=2, label='Real')\n",
    "xticks = np.arange(len(y), step=n_hours)\n",
    "plt.xticks(xticks, x[xticks])\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_t = np.array(maes_h)[:, 0]\n",
    "maes = np.array(maes_h)[:, 1:]\n",
    "for h in range(n_horizon):\n",
    "    plt.plot(hours, maes[h, :], label='H%02d' % (h + 1))\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, maes_t[h]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Cómo compara esta gráfica frente a la del modelo anterior?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a un modelo más complejo ahora, un modelo **ARIMA** que es capaz de modelar las **tendencias**. Probamos primero con un modelo con los mejores hiperparámetros anteriores, pero \"activando\" la `d` para eliminar tendencias.\n",
    "\n",
    "**NOTA:** Es importante tener en cuenta que para obtener los mejores modelos debemos realizar una fase de validación SIEMPRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours=24\n",
    "p=1\n",
    "d=1\n",
    "q=0\n",
    "mod = SARIMAX_train(solar,(p, d, q), n_tr+n_va, period=n_hours)\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué coeficiente está cogiendo ahora para el retraso anterior? ¿Qué significa esto?\n",
    "    \n",
    "* A la vista del modelo construido, ¿crees que mejorará los resultados anteriores?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_h = []\n",
    "n_horizon=6\n",
    "n_hours=24\n",
    "\n",
    "start=n_tr + n_va\n",
    "end=n_tr + n_va + n_te\n",
    "\n",
    "#Reentrenamos con todo el conjunto de entrenamiento y validación \n",
    "mod = SARIMAX_train(solar, (p, d, q), n_tr + n_va, period=n_hours)\n",
    "\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/predARIMA_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)\n",
    "    else:\n",
    "        pred = SARIMAX_predict(mod, solar, start, end, h, period=n_hours)\n",
    "        np.save(file, pred)        \n",
    "    plt.plot(pred[1100:1200], label='H%02d' % (h + 1))\n",
    "    hours, maes = errors_by_hour(solar[start:end], pred, MAE=True)\n",
    "    maes_h.append(maes)\n",
    "    \n",
    "y = solar[start+1100:start+1200]\n",
    "x = y.index\n",
    "plt.plot(y.to_numpy(), 'k', linewidth=2, label='Real')\n",
    "xticks = np.arange(len(y), step=n_hours)\n",
    "plt.xticks(xticks, x[xticks])\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_t = np.array(maes_h)[:, 0]\n",
    "maes = np.array(maes_h)[:, 1:]\n",
    "for h in range(n_horizon):\n",
    "    plt.plot(hours, maes[h, :], label='H%02d' % (h + 1))\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, maes_t[h]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué se aprecia en este modelo?\n",
    "    \n",
    "* ¿A qué crees que pueden deberse estas diferencias?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es aplicar un modelo más complicado que modela también la estacionalidad presente en los datos. Este es el modelo SARIMA.\n",
    "\n",
    "Es importante fijarse en que el objetivo de este modelo es modelar la estacionalidad a la vez que los datos, por lo que NO debemos aplicar diferencias y es importante que el period sea 0.\n",
    "\n",
    "Al igual que en el caso de ARIMA, vamos a asumir como mejores hiperparámetros, los mejores encontrados hasta el momento, es decir `p=1`, `d=0`, `q=0`. Pero ahora debemos definir también los parámetros de la parte estacional. Como no sabemos cuáles serán los mejores, vamos a hiperparametrizarlos, modificando ligeramente la función de validación a estos hiperparámetros. Vamos a probar indicando que hay una estacionbalidad diaria, y por tanto nuestro periodo es de 24 horas (`per=24`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VALIDATE_SEASONAL\n",
    "It obtains the optimal sesonal hyperparameters, based on the MAE as score function\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "horizon : integer\n",
    "          Horizon for the prediction.\n",
    "\n",
    "s : array_like\n",
    "    The complete temporal series (joined in one array or dataframe trainning, \n",
    "    validation and test sets).\n",
    "\n",
    "n_tr : integer\n",
    "       The size of the training set to be considered.\n",
    "\n",
    "n_va : integer\n",
    "       The size of the validation set to be considered.\n",
    "\n",
    "p : integer\n",
    "    AR order.\n",
    "    \n",
    "p : integer\n",
    "    MA order.\n",
    "    \n",
    "d : integer\n",
    "    differentiating order for ARIMA.\n",
    "    \n",
    "per: integer\n",
    "     period for seasonbal evaluation.\n",
    "\"\"\"\n",
    "def validate_seasonal(horizon, s, n_tr, n_va, p, d, q, per):\n",
    "    vec_P = np.arange(3)\n",
    "    vec_Q = np.arange(2)\n",
    "    vec_D = np.arange(2)\n",
    "    \n",
    "    best_e = np.inf\n",
    "    \n",
    "    true = s[n_tr:n_tr + n_va].to_numpy()\n",
    "    for P in vec_P:\n",
    "        for Q in vec_Q:\n",
    "            for D in vec_D:\n",
    "                try:\n",
    "                    print(\"TRAIN %d %d % d\" % (P, D, Q))\n",
    "                    model = SARIMAX_train(s, (p, d, q), n_tr, period=0, seasonal_order=(P,D,Q,per))\n",
    "                    print(\"PRED\")\n",
    "                    pred = SARIMAX_predict(model, s, n_tr, n_tr + n_va, horizon, period=0)\n",
    "                    e = mean_absolute_error(true, pred)\n",
    "                except Exception as exc:\n",
    "                    e = np.inf\n",
    "                if (e < best_e):\n",
    "                    best_e = e\n",
    "                    best_P = P\n",
    "                    best_Q = Q\n",
    "                    best_D = D\n",
    "            \n",
    "                print('%d %d % d => %.4f' % (P, D, Q, e))\n",
    "    \n",
    "    seasonal_order = (best_P, best_D, best_Q, per)\n",
    "    print('\\tBest:', seasonal_order)\n",
    "\n",
    "    return seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1\n",
    "d=0\n",
    "q=0\n",
    "\n",
    "per=24 #Cada 24 datos es un ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '%s/sarima_order.npy' % (output_folder)\n",
    "if isfile(file):\n",
    "    seasonal_order = np.load(file)\n",
    "    print(seasonal_order)\n",
    "else:\n",
    "    seasonal_order = validate_seasonal(0, solar, n_tr, n_va - 6, p, d, q, per)\n",
    "    np.save(file, seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_h = []\n",
    "n_horizon=6\n",
    "\n",
    "start=n_tr + n_va\n",
    "end=n_tr + n_va + n_te\n",
    "\n",
    "#Reentrenamos con todo el conjunto de entrenamiento y validación \n",
    "mod = SARIMAX_train(solar, (p, d, q), n_tr + n_va, period=0, seasonal_order=seasonal_order)\n",
    "\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/predSARIMA_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)\n",
    "    else:\n",
    "        pred = SARIMAX_predict(mod, solar, start, end, h, period=0)\n",
    "        np.save(file, pred)\n",
    "    plt.plot(pred[1100:1200], label='H%02d' % (h + 1))\n",
    "    hours, maes = errors_by_hour(solar[start:end], pred, MAE=True)\n",
    "    maes_h.append(maes)\n",
    "    \n",
    "y = solar[start+1100:start+1200]\n",
    "x = y.index\n",
    "plt.plot(y.to_numpy(), 'k', linewidth=2, label='Real')\n",
    "xticks = np.arange(len(y), step=24)\n",
    "plt.xticks(xticks, x[xticks])\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_t = np.array(maes_h)[:, 0]\n",
    "maes = np.array(maes_h)[:, 1:]\n",
    "for h in range(n_horizon):\n",
    "    plt.plot(hours, maes[h, :], label='H%02d' % (h + 1))\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, maes_t[h]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Qué se aprecia en este modelo?\n",
    "    \n",
    "* ¿Qué diferencias se pueden ver frente a modelos anteriores?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX (variables exógenas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con el mejor modelo anterior. Cogemos SARIMA, aunque solo es mejor en los primeros horizontes.\n",
    "\n",
    "Sobre este modelo vamos a añadir una variable exógena: la variable Gb(i) que representa la radiación directa (en W/m2).\n",
    "\n",
    "El resto de variables presentes en el fichero son:\n",
    "\n",
    "* Gd(i): radiación difusa (W/m2)\n",
    "* Gr(i): radiación reflejada (W/m2)\n",
    "* H_sun: altura del sol (degree)\n",
    "* T2m: temperatura del aire a 2m (degree Celsius)\n",
    "* WS10m: velocidad del viento a 10m (m/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = pd.read_csv('solar.csv',\n",
    "                    header=0, parse_dates=[0], index_col=[0], usecols=[0, 1, 2\n",
    "                                                                      ], \n",
    "                    dayfirst=True, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* A primera vista, ¿qué pinta tienen los datos? ¿Crees que pueden ser de ayuda?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_h = []\n",
    "n_horizon=6\n",
    "\n",
    "#Reutilizamos los valores d elos mejores hiperparámetros obtenidos hasta el momento\n",
    "p=1\n",
    "d=0\n",
    "q=0\n",
    "seasonal_order=(1,1,1,24)\n",
    "\n",
    "start=n_tr + n_va\n",
    "end=n_tr + n_va + n_te\n",
    "\n",
    "#Reentrenamos con todo el conjunto de entrenamiento y validación \n",
    "mod = SARIMAX_train(solar.loc[:,'P'], (p, d, q), n_tr + n_va, period=0, seasonal_order=seasonal_order, \n",
    "                    exog=solar.loc[:,'Gb(i)'])\n",
    "\n",
    "for h in range(n_horizon):\n",
    "    file = '%s/predSARIMAX_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        pred = np.load(file)        \n",
    "    else:\n",
    "        pred = SARIMAX_predict(mod, solar.loc[:,'P'], start, end, h, period=0)\n",
    "        np.save(file, pred)\n",
    "    \n",
    "    plt.plot(pred[1100:1200], label='H%02d' % (h + 1))\n",
    "    hours, maes = errors_by_hour(solar.loc[:,'P'][start:end], pred, MAE=True)\n",
    "    maes_h.append(maes)\n",
    "    \n",
    "y = solar.loc[:,'P'][start+1100:start+1200]\n",
    "x = y.index\n",
    "plt.plot(y.to_numpy(), 'k', linewidth=2, label='Real')\n",
    "xticks = np.arange(len(y), step=24)\n",
    "plt.xticks(xticks, x[xticks])\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_t = np.array(maes_h)[:, 0]\n",
    "maes = np.array(maes_h)[:, 1:]\n",
    "for h in range(n_horizon):\n",
    "    plt.plot(hours, maes[h, :], label='H%02d' % (h + 1))\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, maes_t[h]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* ¿Como compara este modelo frente  a los anteriores?\n",
    "    \n",
    "* ¿Crees que es buena idea utilizar variables exógenas? ¿En este problema o en general? ¿Merecería la pena probar el resto de variables exógenas disponibles?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer por último una pequeña prueba con una red LSTM, estado del arte en predicción de series temporales.\n",
    "\n",
    "Para esto, al corresponderse a un paradigma completamente diferente, necesitaremos nuevos paquetes específicos. Además, estos modelos hay que montarlos en keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from keras.utils import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir primero la red. Keras permite añadir capas cuyas neuronas son celdas **LSTM**.\n",
    "\n",
    "Vamos a definir una arquitectura sencilla, regularizada con un dropout. Al final debemos colocar una capa `Dense` que nos genere la salida de la regresión.\n",
    "\n",
    "Esta arquitectura se puede modificar, añadiendo más unidades y más capas, incluso de otros tipos de redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn():\n",
    "    set_random_seed(123)\n",
    "\n",
    "    rnn = Sequential()\n",
    "    rnn.add(LSTM(200, input_shape=(24, 1)))\n",
    "    rnn.add(Dropout(0.4, input_shape=(1,)))\n",
    "    rnn.add(Dense(1))\n",
    "    rnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este tipo de modelos suele ser importante escalar los datos. \n",
    "\n",
    "Además debemos montar conjuntos diferentes para predecir a distintos horizontes, separando las variables de entrada de las salidas (que son los mismos datos, pero desplazados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(s, h=0, batch_size=32):\n",
    "    y = s[h+1:]\n",
    "    x = s[:-(h+1)]\n",
    "    \n",
    "    x = MinMaxScaler().fit_transform(np.array(x).reshape(-1, 1))\n",
    "    \n",
    "    x, y = x.reshape(-1, 1), y.to_numpy().reshape(-1, 1)\n",
    "    dataset = timeseries_dataset_from_array(x, y, sequence_length=24, batch_size=batch_size)\n",
    "\n",
    "    dataset_tr = dataset.take(int((n_tr + n_va) / batch_size))\n",
    "    dataset_te = dataset.skip(int((n_tr + n_va) / batch_size))\n",
    "    y_te = np.concatenate([batch[1].numpy() for batch in dataset_te])\n",
    "    \n",
    "    return dataset_tr, dataset_te, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro ejemplo, volvemos a cargar los datos sin variables exógenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = pd.read_csv('solar.csv',\n",
    "                    header=0, parse_dates=[0], index_col=[0], usecols=[0, 1], dayfirst=True, \n",
    "                    squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a predecir de nuevo para los distintos horizontes.\n",
    "\n",
    "Aquí también será importante entrenar la red durante un número de épocas suficientes para que la red aprenda. En este caso vamos a dejar muchas épocas para el primer modelo (horizonte 1), y luego vamos a reutilizar lo aprendido por el modelo haciendo uso del *transfer learning*, de forma que con un *fine tunning* de 10 épocas adaptamos lo aprendido a cada cambio de horizonte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn = create_rnn()\n",
    "mae_lstm=[]\n",
    "epochs=[100, 10, 10, 10, 10, 10]\n",
    "\n",
    "for h in range(6):\n",
    "\n",
    "    dataset_tr, dataset_te, y_te = create_dataset(solar, h=h)\n",
    "    \n",
    "    file = '%s/LSTM/predLSTM_H%02d.npy' % (output_folder, h)\n",
    "    if isfile(file):\n",
    "        preds_rnn = np.load(file)\n",
    "    else:\n",
    "        history_rnn = rnn.fit(dataset_tr, epochs=epochs[h], verbose=1)\n",
    "        preds_rnn = rnn.predict(dataset_te, verbose=0)\n",
    "    \n",
    "        np.save(file, preds_rnn)\n",
    "        \n",
    "    if (h == 0):\n",
    "        plt.plot(y_te[1100:1200], \"k\", label='Real')\n",
    "    plt.plot(preds_rnn[1100-h:1200-h], label='H%02d' % (h+1))\n",
    "    mae_lstm.append(mean_absolute_error(y_te, preds_rnn))\n",
    "\n",
    "plt.ylabel(\"Solar Energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pintamos por último los errores obtenidos por horizonte, aunque en este caso no se han calculado por hora.\n",
    "\n",
    "Observa que la gráfica es un poco diferente y pinta el error total para cada horizonte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(6):\n",
    "    plt.plot(mae_lstm, '*-')\n",
    "    print('MAE Total H%02d: %.2f' % (h + 1, mae_lstm[h]))\n",
    "plt.xlabel(\"Horizons\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Observando esta gráfica y la obtenida comparando los datos reales frente a las predicciones, ¿qué conclusiones obtienes?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
