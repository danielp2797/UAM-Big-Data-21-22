{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97bc81e-3853-469a-9b35-a62d34cdee71",
   "metadata": {},
   "source": [
    "# EJERCICIO BÁSICO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e2e6b-b908-4cfe-85cb-ec075cfb5f61",
   "metadata": {},
   "source": [
    "Las funciones que se ocupan del cálculo de los estadísticos pedidos se encuentras en el fichero funciones.py. Se decidió hacer esto para mayor limpieza en la presentación de los ejercicios. Las funciones estan debidamente documentadas en el archivo .py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8504bc56-b996-4c7f-bd71-3acfe3ed82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package \"funciones\" succesfully loaded\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import funciones as udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb306d70-f21a-4c3d-be0a-7adc4c4605ec",
   "metadata": {},
   "source": [
    "Primero se crea la sesion de spark y se declara la ruta que contiene los archivos csv de alturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5a9c09-f99a-4f35-864e-c32030fa8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master = 'local[*]')\n",
    "main_path = '/media/daniel/Seagate Basic/spark_practica1' # path donde se encuantran los csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2abb1b53-acc5-46f8-8dcf-773a506a967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia_alturas(rdd, col=0, sep=','):\n",
    "    \n",
    "    # descripcion\n",
    "    #----------------\n",
    "    \n",
    "    #limpia los datos de alturas. Las tareas de la pipeline son: seaparar las lineas del RDD por el separador argumento\n",
    "    # pasar a centímetros (quitando los puntos), eliminar los números negativos y agregar una cifra a las \n",
    "    # alturas que estando en metros solo tenian un decimal.\n",
    "    \n",
    "    # argumentos:\n",
    "    #----------------\n",
    "    \n",
    "    #<rdd> | tipo: pyspark.rdd \n",
    "    #<col> | tipo: int | descriptivo: columna donde estan las alturas\n",
    "    #<sep> | tipo: str | seapardor del fichero de texto\n",
    "    \n",
    "    # resultado: \n",
    "    #----------------\n",
    "    \n",
    "    #<result> | tipo: pyspark.rdd  | descriptivo: rdd separado por lineas\n",
    "    \n",
    "    rdd_limpio = udf.preprocesa_rdd(rdd)\\\n",
    "                     .map(lambda x: x[:col]+[x[col].replace('.', '')]+x[col+1:])\\\n",
    "                     .filter(lambda x: '-' not in x[col])\\\n",
    "                     .map(lambda x: x[:col]+[float(x[col]+'0')]+x[col+1:] if len(x[col])<3 else x)\n",
    "        \n",
    "    return rdd_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec4909-90cc-4f4a-b6c0-3f587c5c5440",
   "metadata": {},
   "source": [
    "# PRIMERA PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b956c-220a-4de9-a281-3d0dc58da788",
   "metadata": {},
   "source": [
    "Se lee el archivo y cada linea se guarda como un string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312e0e31-f9e7-40bb-9080-27ff4e826b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alturas = f'{main_path}/alturas_v0.csv'\n",
    "rdd_alturas = sc.textFile(alturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa26d4a-8750-4fc9-b320-6623ce017305",
   "metadata": {},
   "source": [
    "Despues se preprocesan los datos, esto es: \n",
    "- Se eliminan los datos negativos\n",
    "- Se pasan todas las observaciones a centímetros.\n",
    "- Se añade un 0 a las observaciones en metros dadas con una única cifra significativa.\n",
    "\n",
    "Además, las funciones que obtienen los resultados pedidos siempre necesitan una columna por la que agregar. Para eso, se crea la clave 'global' para todas las observaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcb36b3e-4f4e-4b41-9cc8-41227e937ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_alturas_limpio = limpia_alturas(rdd_alturas).map(lambda x: ['global']+ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c702305-1104-4e12-99a6-af166266caa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('global', (168.93825222396651,))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medias = udf.summary(rdd_alturas_limpio, features=[1], agg=[0], std=['mean'])\n",
    "medias.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e1606c9-d273-4f46-8283-50cda2a9bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('global', (7.8340557833708955,))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = udf.summary(rdd_alturas_limpio, features=[1], agg=[0], std=['std'])\n",
    "std.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af4cce-7c68-49aa-bab0-ec8d895df13c",
   "metadata": {},
   "source": [
    "# SEGUNDA PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfcd29-59f0-42b9-851c-5f71b6ad021e",
   "metadata": {},
   "source": [
    "En esta segunda parte, se calculan los estadísticos agregando por sexo. Se repite el proceso anteriormente descrito y para el cálculo se usan las funciones desarrolladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53f89560-8149-49e6-99a5-bc3378aafdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alturas2 = f'{main_path}/alturas.csv'\n",
    "rdd_alturas2 = sc.textFile(alturas2)\n",
    "\n",
    "rdd_alturas_limpio2 = limpia_alturas(rdd_alturas2, col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51d6fba7-71fa-4929-9dfd-464298d962d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('H', (173.46075433231397,)), ('M', (164.16774193548386,))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medias = udf.summary(rdd_alturas_limpio2, features=[1], agg=[0], std=['mean'])\n",
    "medias.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ca01cc-ce85-424a-85d2-0049c87360d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('H', (7.53122883663738,)), ('M', (4.684891325217995,))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = udf.summary(rdd_alturas_limpio2, features=[1], agg=[0], std=['std'])\n",
    "std.take(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
